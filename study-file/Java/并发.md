# 并发

-   **并发**：两个及两个以上的作业在同一 **时间段** 内执行。举一个例子 500个请求同时打到一台只有1核cpu的机器上，此时cpu需要来回切换去执行这五百个任务。（微观`不是同时执行`）
-   **并行**：两个及两个以上的作业在同一 **时刻** 执行。同样500个请求同时打到一台500核cpu的机器上，则可以不用切换同时都执行任务。



**多线程**

```
指的是这个程序（一个进程）运行时产生了不止一个线程，多线程是并发的一种体现。
```

**并发编程下安全问题**

```
内存泄漏、死锁、线程不安全（对于同一份数据，多个线程同时访问时可能会导致数据混乱、错误或者丢失）
```



**java创建线程的方式有哪些**

```
1.继承 Thread 类
2.实现 Runnable 接口
3.实现 Callable 接口
4.线程池
```



#### 线程状态

```markdown
1. NEW: 初始状态，线程被创建出来但没有被调用 start() 。
2. RUNNABLE: 运行状态，线程被调用了 start()等待运行的状态。
3. BLOCKED：阻塞状态，需要等待锁释放。
		1.wait被notify()后重新获取锁失败。
		2.synchronized方法/代码块未获取到锁。
4. WAITING：等待状态，表示该线程需要等待其他线程做出一些特定动作（通知或中断）。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态。
		调用线程的wait/join方法,跟超时等待的区别就是没有时间限制。
5. TIME_WAITING：超时等待状态，可以在指定的时间后自行返回而不是像 WAITING 那样一直等待。
        调用线程的sleep/join(time)/wait(time)方法，或者发出io请求时，线程就会进入阻塞状态，当线程sleep超时，join等待线程终止或者超时，io处理完毕后，线程就会重新进入就绪状态。
6. TERMINATED：终止状态，表示该线程已经运行完毕。
```



<img src="./img/640.png" alt="Java 线程状态变迁图" style="zoom:50%;" />



#### 线程上下文切换

```markdown
线程在执行过程中会有自己的运行条件和状态（也称上下文），比如上文所说到过的程序计数器，栈信息等。当出现如下情况的时候，线程会从占用 CPU 状态中退出。
    主动让出 CPU，比如调用了 sleep(), wait() 等。
    时间片用完，因为操作系统要防止一个线程或者进程长时间占用 CPU 导致其他线程或者进程饿死。
    调用了阻塞类型的系统中断，比如请求 IO，线程被阻塞。
    被终止或结束运行
```

>   CPU时间片切换时，会触发线程上下文切换。



**Thread类中start()和run()方法区别**

```
线程对象调用run方法不开启线程。仅是对象调用方法。
线程对象调用start开启线程，并让jvm调用run方法在开启的线程中执行
调用start方法可以启动线程，并且使得线程进入就绪状态，而run方法只是thread的一个普通方法，还是在主线程中执行。
```

**Thread类中wait()和sleep()方法区别**

```markdown
wait和sleep方法都会使当前线程暂时放弃cpu使用权，进入阻塞状态，都可以被interrupt打断唤醒。
    wait通常被用于线程间交互/通信，sleep通常被用于暂停执行。
    wait在阻塞中会释放锁，sleep不会释放锁。
    wait是object类的方法，sleep是thread类的方法。
```

>   wait() 是让获得对象锁的线程实现等待，会自动释放当前线程占有的对象锁。每个对象（Object）都拥有对象锁，既然要释放当前线程占有的对象锁并让其进入 WAITING 状态，自然是要操作对应的对象（Object）而非当前的线程（Thread）。
>
>   sleep() 是让当前线程暂停执行，不涉及到对象类，也不需要获得对象锁

**Java中Runnable和Callable有什么不同**

```markdown
runnable接口中run方法是没有返回值的,只是纯粹的去执行run()方法中的代码
callable中的call()方法是有返回值的，是一个泛型，和Future、FutureTask配合可以用来获取异步执行的结果。
```



#### 线程同步

保证线程之间按照规定的先后次序运行。

-   **互斥锁**：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。
-   **读写锁**：允许多个线程同时读取共享资源，但只有一个线程可以对共享资源进行写操作。
-   **信号量**：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。`Semaphore`
-   **屏障**：屏障是一种同步原语，用于等待多个线程到达某个点再一起继续执行。当一个线程到达屏障时，它会停止执行并等待其他线程到达屏障，直到所有线程都到达屏障后，它们才会一起继续执行。`CyclicBarrier`
-   **事件**：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。

>   **进程通信**
>
>   1.  **管道/匿名管道(Pipes)**：用于具有亲缘关系的父子进程间或者兄弟进程之间的通信。
>   2.  **有名管道(Named Pipes)** : 匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。有名管道严格遵循 **先进先出(First In First Out)** 。有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。
>   3.  **信号(Signal)**：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；
>   4.  **消息队列(Message Queuing)**：消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显式地删除一个消息队列时，该消息队列才会被真正的删除。消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比 FIFO 更有优势。**消息队列克服了信号承载信息量少，管道只能承载无格式字 节流以及缓冲区大小受限等缺点。**
>   5.  **信号量(Semaphores)**：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。
>   6.  **共享内存(Shared memory)**：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。
>   7.  **套接字(Sockets)** : 此方法主要用于在客户端和服务器之间通过网络进行通信。套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。



#### 死锁

```markdown
就是多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。


# 死锁的产生条件
1.互斥条件:一个资源每次只能被一个进程使用;
2.请求与保持条件:一个进程因请求资源而阻塞时,对已获得的资源保持不放;
3.不剥夺条件:进程已获得的资源,在末使用完之前,不能强行剥夺;
4.循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系;

# 预防死锁
    破坏请求与保持条件：一次性申请所有的资源。
    破坏不剥夺条件：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
    破坏循环等待条件：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。
# 避免死锁
    1. 设置超时时间
    2. 多使用JUC包提供的并发类,而不是自己设计锁
    3. 尽量降低锁的使用粒度
    4. 避免锁的嵌套
```







#### 并发的三大特性

```markdown
1.原子性
		一个操作是不可中断，即使有多个线程执行，一旦操作开始也不会受其他线程影响，即可以理解为线程的最小执行单元，不可被分割
2.可见性
		当某个线程修改了其内存中共享变量的值时，其他线程能立刻感知到其值的变化
3.有序性
		程序按一定规则进行顺序的执行，期间会进行编译器优化重排、指令重排、内存重排等，执行规则遵循as-if-serial语义规则和happens-before 原则
```



#### JMM内存模型

```markdown
工作流程
    由于JVM运行程序的实体是线程，每个线程创建jvm都会为其创建一个工作内存(有些地方称为栈空间)，工作内存是每个线程的私有数据区域，而java内存模型中规定所有变量都存储在主内存，主内存是共享内存，所有的线程都可以访问，但线程对变量的操作（读取赋值等）必须在工作内存中进行，首先要将变量从主内存拷贝到自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，不能直接操作主内存中的变量，各个线程中的工作内存中存储着主内存中的变量副本拷贝，因此不同的线程间无法访问对方的工作内存，线程间的通信（传值）必须通过主内存来完成。
规定：		
		1.线程解锁前，必须把共享变量的值刷新回主内存。
		2.线程加锁前，必须读取主内存的最新值到自己的工作内存。
		3.加锁解锁是同一把锁。
```



#### volatile

```markdown
1. 概念:
		一种java虚拟机提供的轻量级的同步机制
2. 特性:
		a.保证可见性（通过内存屏障保证可见性）
		b.不保证原子性
		c.禁止指令重排（保证有序性）
		
volatile实现禁止指令重排优化，从而避免多线程环境下程序出现乱序的现象。

3. 适用场景（在哪些地方用过volatile）：
	    1.单例模式，通过DCL机制
	    2.读写锁，手写缓存
	    3.CAS底层的juc也用volatile
```



> 1.double check lock双端检锁机制，底层变量使用volatile修饰，对象创建时进行synchronized加锁
>
> 2.dcl机制存在线程安全问题，当对象初始化时，由于指令重排可能会导致对象未初始化时，就获取实例对象来指定内存地址，导致异常报错
>
> 正常new对象分为3步：
>
> 1.  为实例分配内存空间
> 2.  初始化实例
> 3.  将引用指向分配的内存地址



**内存屏障（Memory Barrier）**

```markdown
概念：内存栅栏，是一个CPU指令
作用：
	1.禁止指令重排
	2.保证某些变量的内存可见性（利用该特性实现volatile的内存可见性）

工作原理：
	由于编译器和处理器都能执行指令重排优化。如果在指令间插入一条Memory Barrier则会告诉编译器和CPU，不管什么指令都不能和这条Memory Barrier指令重排序，通过插入内存屏障禁止在内存屏障前后的指令执行重排序优化。内存屏障另一个作用就强制刷出各种CPU的缓存数据，因此任何CPU上的线程都能读取到这些数据的最新版本。
	
	1.对Volatile变量进行写操作时：
		会在写操作后加入一条store屏障指令，将工作内存中的共享变量值刷新回主内存。
	2. 对Volatile变量进行读操作时：
		会在读操作前加入一条load屏障指令，从主内存中读取共享变量。
```

> 指令重排只会保证串行语句的一致性。
>
> `Unsafe` 类提供了三个开箱即用的内存屏障相关的方法。

**问题**

1.  工作内存和主内存同步延迟现象导致的可见性问题

    可以使用synchronize或volatile关键字解决，它们都可以使<font color='red'>一个线程修改后的变量立即对其他线程可见</font>。

2.  对于指令重排导致的可见性问题和有序性问题。

    可以利用volatile关键字解决，因为volatile的另外一个作用就是禁止重排序优化。

#### CAS

```markdown
1. 应用场景：
        整个AQS同步组件、Atomic原子类操作等等都是以CAS实现的
        ConcurrentHashMap在1.8的版本中也调整为了CAS+Synchronized。可以说CAS是整个JUC的基石。
2. 概念
    	物理内存中的值：主内存值
    	期望值：工作内存值
    	值偏移量：值的地址
    	当前线程会携带自身工作内存中的值（主内存值的快照）和值偏移量进入方法，通过getIntVolatile方法取出主内存的值,调用compareAndSwapInt与主内存中值进行比较，如果相等会进行修改操作，不相等就会进行do-while循环，重新获取工作内存的资源。
3. 工作原理
    	调用Unsafe类中的CAS方法，JVM会帮我们实现CAS汇编指令，是一种完全依赖于硬件的功能，通过它实现了原子操作，是由多个指令组成的，用于完成某个功能的一个过程，并且这些指令的执行必须是连续的，在执行过程中不允许中断，不会造成数据不一致的问题。
4. 缺点
    	1.循环时间长，开销大
    		如果CAS失败，会一直进行尝试，会一直占用CPU带来很大的开销。
    	2.只能保证一个变量的原子性，对于多个共享变量操作，要使用加锁来保证原子性。
    	3.ABA问题
    		通过AtomicStampedReference<V>原子类解决，原子类+时间戳（版本号）;
```





#### sychronized

```markdown
1. 实现原理：
		jvm基于Monitor对象来实现方法的同步和代码块的同步
2. 执行流程
		1.每个锁对象都会关联一个monitor(监视器,它才是真正的锁对象),它内部有两个重要的成员变量，owner会保存获得锁的线程,recursions会保存线程获得锁的次数,会在代码块前加入monitorEnter指令，代码块尾部加入monitorexit指令,每执行一次monitorEnter会将recurions加1,当执行到monitorexit时,recursions会-1,当计数器减到0时这个线程就会释放锁
		2.修饰方法时只有ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法。
# JDK1.6 对锁的实现引入了大量的优化，
	如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。
    锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。

1.当修饰静态方法和修饰代码块的时候，锁的是当前类的class对象。
2.当修饰实例方法时，锁的就是当前类的实例对象。
3.synchronized(String a) 因为 JVM 中，字符串常量池具有缓存功能
```



>   `wait/notify`等方法也依赖于`monitor`对象，这就是为什么只有在同步的块或者方法中才能调用`wait/notify`等方法，否则会抛出`java.lang.IllegalMonitorStateException`的异常的原因。

>   -   对象在刚创建时为无锁状态
>   -   当有一个线程使用这个对象的时候，此时升级为偏向锁，在对象头中标记为偏向锁，当下次这个线程再次访问这个对象时，直接使用；
>   -   当对象通过CAS实现获取锁的时候，此时锁从偏向锁升级为轻量级锁
>   -   当有更多的线程竞争这个对象的时候，此时轻量级锁升级为重量级锁

**synchronized与lock的区别**

```markdown
1. Lock 是 API层面，是java5以后新出现的一个类，synchronized 是 JVM 级别的是java关键字
2. synchronized不需要用户手动释放锁对象，当synchronized代码执行完后系统会自动让线程释放对锁的占用，而lock需要手动释放锁对象，若没有主动释放锁，有可能导致死锁现象出现
3. synchronized不可中断，除非抛出异常或者正常运行完成
		1.lock可中断，设置超时方法tryLock(Long time,TimeUnit unit)，到指定时间后会尝试获取锁，获取不到就直接中断。
		2.lockInterruptibly()能够中断等待锁的线程。
3. synchronized是非公平锁，reentrantlock指定锁类型。
4. synchronized只能通过wait+notify/notifyAll实现等待通知, ReentrantLock 通过 Condition 可以绑定多个条件，达到精确唤醒线程。
5. ReentrantLock底层调用的是Unsafe的park方法加锁，synchronized操作的应该是对象头中mark word.
```

>   interrupt（）是给线程设置中断标志；
>
>   interrupted（）是检测中断并清除中断状态；
>
>   isInterrupted（）只检测中断。
>
>   还有重要的一点就是interrupted（）作用于当前线程，interrupt（）和isInterrupted（）作用于此线程，即代码中调用此方法的实例所代表的线程。





#### 锁

```markdown
# 乐观锁
	操作数据时不会对操作的数据进行加锁，只有到数据提交的时候才通过一种机制来验证数据是否存在冲突（可以使用版本号机制和CAS）
	1.ABA问题。
	2.性能问题。
	3.只能保证一个共享变量的原子性问题。
# 悲观锁
	共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程。
1. 悲观锁通常多用于写比较多的情况（多写场景，竞争激烈），这样可以避免频繁失败和重试影响性能，悲观锁的开销是固定的。不过，如果乐观锁解决了频繁失败和重试这个问题的话（比如LongAdder），也是可以考虑使用乐观锁的，要视实际情况而定。
2. 乐观锁通常多用于写比较少的情况（多读场景，竞争较少），这样可以避免频繁加锁影响性能。不过，乐观锁主要针对的对象是单个共享变量（参考java.util.concurrent.atomic包下面的原子变量类）。

# 公平锁：
	指多个线程按照申请锁的顺序来获取锁.

# 非公平锁：
	指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁在高并发的情况下，有可能造成优先级反转或者饥饿现象
区别：
		1.公平锁在并发环境下，每个线程在获取锁时会先查看此锁维护的等待队列，如果为空或者当前线程是等待队列的第一个，就会占有锁，否则就会加入到等待队列，按照FIFO规则（先进先出）从队列中取到自己
        2.非公平锁上来就会尝试占有锁，如果尝试失败，就采用类似公平锁的方式加入等待队列
		3.非公平锁的吞吐量比公平锁大
# 可重入锁（递归锁）
1. 概念：
		同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁。
2. 作用：
		避免死锁
# 自旋锁（SpinLock）
1. 概念：
		指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁。
		循环比较获取直到成功为止，没有类似wait的阻塞，底层是CAS机制。
2. 优缺点：
		减少线程上下文切换的消耗.
		循环会消耗CPU.
# 独占锁（写锁）
1. 概念
		该锁只能被一个线程所持有
# 共享锁（读锁）
1. 概念
		该锁可被多个线程所持有
# 可中断锁：
    获取锁的过程中可以被中断，不需要一直等到获取锁之后 才能进行其他逻辑处理。ReentrantLock 就属于是可中断锁。
# 不可中断锁：
    一旦线程申请了锁，就只能等到拿到锁以后才能进行其他的逻辑处理。 synchronized 就属于是不可中断锁。
```

>   reentrantlock：默认非公平锁，可重入锁，悲观锁，独占锁
>
>   synchronized：非公平锁，可重入锁，悲观锁，独占锁
>
>   -   一般锁进行并发控制的规则：读读互斥、读写互斥、写写互斥。
>   -   读写锁进行并发控制的规则：读读不互斥、读写互斥、写写互斥（只有读读不互斥）。







**synchronized和volatie的区别**

```
volatile本质是告诉JVM当前变量在寄存器中的值是不确定的，需要从主存中读取。synchronized则是锁定当前变量，只有当前线程可以访问该变量，其它线程被阻塞。
volatile仅能使用在变量级别，synchronized则可以使用在变量、方法。
volatile仅能实现变量修改的可见性，而synchronized则可以保证变量修改的可见性和原子性。《Java编程思想》上说，定义long或double时，如果使用volatile关键字(简单的赋值与返回操作)，就会获得原子性。(常规状态下，这两个变量由于其长度，其操作不是原子的)
volatile不会造成线程阻塞，synchronized会造成线程阻塞。
使用volatile而不是synchronized的唯一安全情况是类中只有一个可变的域。
```



#### AQS

```markdown
1.AQS (AbstractQueuedSynchronizer) 是一个用来构建锁和同步器的框架，核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用CLH 队列锁实现的，即将暂时获取不到锁的线程加入到队列中。
2.核心流程：
	独占：
        1.内部维护了一个 state 变量，用来表示锁的占用状态，state 的初始值为 0，表示锁处于未锁定状态
        2.当线程 A 调用 lock() 方法时，会尝试通过 tryAcquire() 方法独占该锁，并让 state 的值加 1。
        3.如果成功了，那么线程 A 就获取到了锁。如果失败了，那么线程 A 就会被加入到一个等待队列（CLH 队列）中，直到其他线程释放该锁。
        4.假设线程 A 获取锁成功了，释放锁之前，A 线程自己是可以重复获取此锁的（state 会累加）。这就是可重入性的体现：一个线程可以多次获取同一个锁而不会被阻塞。但是，这也意味着，一个线程必须释放与获取的次数相同的锁，才能让 state 的值回到 0，也就是让锁恢复到未锁定状态。只有这样，其他等待的线程才能有机会获取该锁。
	共享：
        1.任务分为 N 个子线程去执行，state 也初始化为 N（注意 N 要与线程个数一致）。
        2.这 N 个子线程开始执行任务，每执行完一个子线程，就调用一次 countDown() 方法。该方法会尝试使用 CAS(Compare and Swap) 操作，让 state 的值减少 1。
        3.当所有的子线程都执行完毕后（即 state 的值变为 0），CountDownLatch 会调用 unpark() 方法，唤醒主线程。这时，主线程就可以从 await() 方法（CountDownLatch 中的await() 方法而非 AQS 中的）返回，继续执行后续的操作
3.实现：
	1.独占：tryAcquire-tryRelease（ReentrantLock、Share）
	2.共享：tryAcquireShared-tryReleaseShared（Semaphore、CountDownLatch）
```



#### 常见同步器（JUC同步工具）

```markdown
Semaphore(信号量)：控制同时访问特定资源的线程数量
	公平模式： 调用 acquire() 方法的顺序就是获取许可证的顺序，遵循 FIFO；
    非公平模式： 抢占式的。
    应用场景：限流
CountDownLatch(倒计时器)：会把指定数量线程阻塞在一个地方，直至所有线程的任务都执行完毕
	应用场景：
		1.启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行；
		2.实现多个线程开始执行任务的最大并行；
CyclicBarrier(循环栅栏)：让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活
```



#### ThreadLocal

```markdown
作用：
    1.传递数据
    2.线程隔离
    在同步机制中，通过对象的锁机制保证同一时间只有一个线程访问变量。

而ThreadLocal则从另一个角度来解决多线程的并发访问。ThreadLocal会为每一个线程提供一个独立的变量副本，从而隔离了多个线程对数据的访问冲突。
ThreadLocal在每个本地线程中创建了一个ThreadLocalMap对象，每个线程可以访问自己内部ThreadLocalMap对象里的value。通过这种方式，实现线程之间的数据隔离。
应用场景：
	1.使用线程池时，传递用户数据，每个用户的数据都是独立的，但是在子线程中获取不到上层的用户数据，需要用到ThreadLocal进行用户数据传递。

问题：ThreadLocal 内存泄露问题是怎么导致的？
    这样一来，ThreadLocalMap 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远无法被 GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap 实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal方法后最好手动调用remove()方法

```







### 3.线程池

```markdown
2. 特点：线程复用，控制最大并发数，管理线程
3. 好处：
		1.降低资源消耗，通过重复利用已创建的线程降低线程的创建和销毁时的资源消耗。
		2.提高响应速度，当任务到达时，任务可以不需要等待线程创建就能立即执行。
		3.提高线程的可管理性，使用线程池可以对线程进行统一的分配，调优和监控
4. 线程池的创建方式：
		Executors类也是一种常用的创建线程池的方式。
		new ThreadPoolExecutor();
# 5. 七大参数：
		int corePoolSize:线程数
        int maximumPoolSize:线程池最大容量
        long keepAliveTime:线程保留时间
        TimeUnit unit:时间类型
        BlockingQueue<Runnable> workQueue:工作队列
        ThreadFactory threadFactory:线程工厂
        RejectedExecutionHandler handler:拒绝策略（接口）
# 6. 工作原理：
		如果当前运行的线程数小于核心线程数，那么就会新建一个线程来执行任务。
        如果当前运行的线程数等于或大于核心线程数，但是小于最大线程数，那么就把该任务放入到任务队列里等待执行。
        如果向任务队列投放任务失败（任务队列已经满了），但是当前运行的线程数是小于最大线程数的，就新建一个线程来执行任务。
        如果当前运行的线程数已经等同于最大线程数了，新建线程将会使当前运行的线程超出最大线程数，那么当前任务会被拒绝，饱和策略会调用RejectedExecutionHandler.rejectedExecution()方法。
# 7. 拒绝策略
		第一种AbortPolicy:不执行新任务，直接抛出异常，提示线程池已满
        第二种DisCardPolicy:不执行新任务，也不抛出异常
        第三种DisCardOldSetPolicy:将任务队列中的第一个任务替换为当前新进来的任务执行
        第四种CallerRunsPolicy:直接调用execute来执行当前任务
# 8. 线程池类型
        CachedThreadPool:可缓存的线程池，该线程池中没有核心线程，非核心线程的数量为Integer.max_value，就是无限大，当有需要时创建线程来执行任务，没有需要时回收线程，适用于耗时少，任务量大的情况。
        ScheduledThreadPool:周期性执行任务的线程池，按照某种特定的计划执行线程中的任务，有核心线程，但也有非核心线程，非核心线程的大小也为无限大。适用于执行周期性的任务。
        SingleThreadPool:只有一条线程来执行任务，适用于有顺序的任务的应用场景。
        FixedThreadPool:定长的线程池，有核心线程，核心线程的即为最大的线程数量。
# 9. 阻塞队列
		容量为 Integer.MAX_VALUE 的 LinkedBlockingQueue（无界队列）：FixedThreadPool 和 SingleThreadExector 。由于队列永远不会被放满，因此FixedThreadPool最多只能创建核心线程数的线程，SingleThreadExector只能创建一个线程。
        SynchronousQueue（同步队列）：CachedThreadPool 。SynchronousQueue 没有容量，不存储元素，目的是保证对于提交的任务，如果有空闲线程，则使用空闲线程来处理；否则新建一个线程来处理任务。也就是说，CachedThreadPool 的最大线程数是 Integer.MAX_VALUE ，可以理解为线程数是可以无限扩展的，可能会创建大量线程，从而导致 OOM。
        DelayedWorkQueue（延迟阻塞队列）：ScheduledThreadPool。DelayedWorkQueue 的内部元素并不是按照放入的时间排序，而是会按照延迟的时间长短对任务进行排序，内部采用的是“堆”的数据结构，可以保证每次出队的任务都是当前队列中执行时间最靠前的。DelayedWorkQueue 添加元素满了之后会自动扩容原来容量的 1/2，即永远不会阻塞，最大扩容可达 Integer.MAX_VALUE，所以最多只能创建核心线程数的线程。
```

>   动态改变线程池参数：核心线程数量，最大线程容量，队列大小，通过set方法进行设置，在运行时可以直接覆盖掉对应属性值；参考美团。

>   自定义根据任务的优先级来执行的线程池：使用PriorityBlockingQueue（优先级阻塞队列），无界阻塞队列；
>
>   排序：
>
>   1.  提交到线程池的任务实现 `Comparable` 接口，并重写 `compareTo` 方法来指定任务之间的优先级比较规则。
>   2.  创建 `PriorityBlockingQueue` 时传入一个 `Comparator` 对象来指定任务之间的排序规则(推荐)。
>
>   风险和解决方案：
>
>   -   `PriorityBlockingQueue` 是无界的，可能堆积大量的请求，从而导致 OOM。重写队列入队逻辑；
>   -   可能会导致饥饿问题，即低优先级的任务长时间得不到执行。通过判断等待时间，如果等待时间过长的任务会被移除并重新添加到队列中，但是优先级会被提升。
>   -   由于需要对队列中的元素进行排序操作以及保证线程安全（并发控制采用的是可重入锁 `ReentrantLock`），因此会降低性能，无法避免。







终止任务最好的方法是设置一个任务会定期检查的标识，由此任务可以通过自己的关闭流程来优雅地终止。



死锁产生条件：

- 互斥，线程任务中存在一项非共享资源。
- 一个任务必须持有一项资源，并且等待正在被另一个线程持有的资源
- 不能从一个线程中抢走资源
- 循环等待：一个任务等待另一个任务持有的资源，另一个任务等待别的任务或者当前任务持有的资源。



Java上下文切换：

- 保存要挂起的线程的当前状态
- 读取要继续执行的线程进行挂起状态时（所保存）的实时状态



设置Java线程数量：对于计算密集型任务：线程数 = 物理核心 （CPU 核心数量）



所有线程都不允许抛出未捕获的checked exception（比如sleep时的InterruptedException），也就是说各个线程需要自己把自己的checked exception处理掉。这一点是通过java.lang.Runnable.run()方法声明(因为此方法声明上没有throw exception部分)进行了约束。但是线程依然有可能抛出unchecked exception（如运行时异常），当此类异常跑抛出时，线程就会终结，而对于主线程和其他线程完全不受影响，且完全感知不到某个线程抛出的异常(也是说完全无法catch到这个异常)。JVM的这种设计源自于这样一种理念：线程是独立执行的代码片断，线程的问题应该由线程自己来解决，而不要委托到外部。”“基于这样的设计理念，在Java中，线程方法的异常（无论是checked还是unchecked exception），都应该在线程代码边界之内（run方法内）进行try catch并处理掉 此方法引发的任何异常都将被 Java 虚拟机忽略。.换句话说，我们不能捕获从线程中逃逸的异常。
