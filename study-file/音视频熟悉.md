

### 1.协议与格式

```
音视频输入协议(主流)：UDP-TS、RTMP、HTTP-HLS、HTTP-TS、HTTP-FLV、RTSP等
音视频输出协议：UDP、HLS、RTMP、HTTP-TS等

常见的直播流协议有：RTMP、RTSP、HTTP 等；
常见的点播协议有：MP4、FLV、HLS 等。

点播素材：
 主流编码格式：H.264、AVS+、H.265等
 主流视频格式（封装格式）：DVD、DAT、MPEG、AVI、MKV、FLV、WMV、MP4、m3u8、VOB、RMVB、ASF、MP3、WMA、S48、TS等
```

**主要流媒体协议一览**

| 名称     | 推出即构  | 传输层协议 | 客户端   | 使用领域        |
| -------- | --------- | ---------- | -------- | --------------- |
| RTSP+RTP | IETF      | TCP+UDP    | VLC, WMP | IPTV            |
| RTMP     | Adobe     | TCP        | Flash    | 互联网直播      |
| RTMFP    | Adobe     | UDP        | Flash    | 互联网直播      |
| MMS      | Microsoft | TCP/UDP    | Flash    | 互联网直播+点播 |
| HTTP     | WWW       | TCP        | Flash    | 互联网点播      |

RTSP+RTP经常用于IPTV领域。因为其采用UDP传输视音频，支持组播，效率较高。但其缺点是网络不好的情况下可能会丢包，影响视频观看质量。

因为互联网网络环境的不稳定性，**RTSP+RTP较少用于互联网视音频传输**。**互联网视频服务通常采用TCP作为其流媒体的传输层协议**，因而像**RTMP**，MMS，**HTTP**这类的协议广泛用于互联网视音频服务之中。这类协议不会发生丢包，因而保证了视频的质量，但是传输的效率会相对低一些。

此外RTMFP是一种比较新的流媒体协议，特点是支持P2P。





### 2.视频播放器原理

视频在传输过程中经过媒体服务器可能发生再次编码和解码，用户如果需要观看视频还是要通过视频播放器内部解码才能观看。



视频播放器在线播放，需要经过以下几个步骤：

1.  解协议
2.  解封账
3.  解码音视频
4.  音视频同步

播放本地文件，步骤如下：

1.  解封装
2.  解码音视频
3.  音视频同步

具体过程：

![img](https://pic3.zhimg.com/80/v2-c1c8cbd7e87f3cc7cb016a713fdb5162_720w.jpg)





**1. 解协议**

解协议的作用，就是将流媒体协议的数据，解析为标准的相应的封装格式数据。视音频在网络上传播的时候，常常采用各种流媒体协议，例如HTTP，RTMP，或是MMS等等。这些协议在传输视音频数据的同时，也会传输一些信令数据。这些信令数据包括对播放的控制（播放，暂停，停止），或者对网络状态的描述等。解协议的过程中会去除掉信令数据而只保留视音频数据。例如，采用RTMP协议传输的数据，经过解协议操作后，输出FLV格式的数据。

**2. 解封装**

解封装的作用，就是将输入的封装格式的数据，分离成为音频流压缩编码数据和视频流压缩编码数据。封装格式种类很多，例如MP4，MKV，RMVB，TS，FLV，AVI等等，它的作用就是将已经压缩编码的视频数据和音频数据按照一定的格式放到一起。例如，FLV格式的数据，经过解封装操作后，输出H.264编码的视频码流和AAC编码的音频码流。

**3.解码**

解码的作用，就是将视频/音频压缩编码数据，解码成为非压缩的视频/音频原始数据。音频的压缩编码标准包含AAC，MP3，AC-3等等，视频的压缩编码标准则包含H.264，MPEG2，VC-1等等。解码是整个系统中最重要也是最复杂的一个环节。通过解码，压缩编码的视频数据输出成为非压缩的颜色数据，例如YUV420P，RGB等等；压缩编码的音频数据输出成为非压缩的音频抽样数据，例如PCM数据。

**4. 视音频同步**

视音频同步的作用，就是根据解封装模块处理过程中获取到的参数信息，同步解码出来的视频和音频数据，并将视频音频数据送至系统的显卡和声卡播放出来。





### 3.视频编码格式

**所谓编码，其本质就是将数据<font color="red">压缩</font>，进而减少带宽或存储空间的占用。**

视频编码的主要作用是将视频像素数据（RGB，YUV等）压缩成为视频码流，从而降低视频的数据量。如果视频不经过压缩编码的话，体积通常是非常大的，一部电影可能就要上百G的空间。视频编码是视音频技术中最重要的技术之一。视频码流的数据量占了视音频总数据量的绝大部分。高效率的视频编码在同等的码率下，可以获得更高的视频质量。



**主要视频编码一览**

| 名称        | 推出机构   | 推出时间 | 目前使用领域 |
| ----------- | ---------- | -------- | ------------ |
| HEVC(H.265) | MPEG/ITU-T | 2013     | 研发中       |
| H.264       | MPEG/ITU-T | 2003     | 各个领域     |
| MPEG4       | MPEG       | 2001     | 不温不火     |
| MPEG2       | MPEG       | 1994     | 数字电视     |
| VP9         | Google     | 2013     | 研发中       |
| VP8         | Google     | 2008     | 不普及       |
| VC-1        | Microsoft  | 2006     | 微软平台     |

有两种视频编码方案是最新推出的：VP9和HEVC。目前这两种方案都处于研发阶段，还没有到达实用的程度。当前使用最多的视频编码方案就是H.264（**编码标准**）。



音频的原始数据格式主要有如下几种：

-   PCM 格式

音频的编解码标准主要有如下几种：

-   MP3
-   AAC
-   AC-3

视频的原始数据格式主要有如下几种：

-   YUV 格式
-   RGB 格式

视频的编解码标准主要有如下几种：

-   H.264
-   H.265
-   MPEG2



**主要音频编码一览**

| 名称 | 推出机构  | 推出时间 | 目前使用领域   |
| ---- | --------- | -------- | -------------- |
| AAC  | MPEG      | 1997     | 各个领域（新） |
| AC-3 | Dolby     | 1992     | 电影           |
| MP3  | MPEG      | 1993     | 各个领域（旧） |
| WMA  | Microsoft | 1999     | 微软平台       |

音频编码技术近期绝大部分的改动都是在MP3的继任者——AAC的基础上完成的。







### 4.封装格式

封装格式的主要作用是把视频码流和音频码流按照一定的格式存储在一个文件中。

主要封装格式一览

| 名称 | 推出即构      | 流媒体 | 支持的视频编码                 | 支持的音频编码                        | 使用领域       |
| ---- | ------------- | ------ | ------------------------------ | ------------------------------------- | -------------- |
| AVI  | Microsoft     | 不支持 | 几乎所有格式                   | 几乎所有格式                          | BT下载影视     |
| MP4  | MPEG          | 支持   | MPEG-2, MPEG-4, H.264, H.263等 | AAC, MPEG-1 Layers I, II, III, AC-3等 | 互联网视频网站 |
| TS   | MPEG          | 支持   | MPEG-1, MPEG-2, MPEG-4, H.264  | MPEG-1 Layers I, II, III, AAC         | IPTV，数字电视 |
| FLV  | Adobe         | 支持   | Sorenson, VP6, H.264           | MP3, ADPCM, Linear PCM, AAC等         | 互联网视频网站 |
| MKV  | CoreCodec     | 支持   | 几乎所有格式                   | 几乎所有格式                          | 互联网视频网站 |
| RMVB | Real Networks | 支持   | RealVideo 8, 9, 10             | AAC, Cook Codec, RealAudio Lossless   | BT下载影视     |

除了AVI之外，其他封装格式都支持流媒体，即可以“边下边播”。有些格式更“万能”一些，支持的视音频编码标准多一些，比如MKV。而有些格式则支持的相对比较少，比如说RMVB





### 5.常见概念理解



#### a.	IDR(即时解码刷新)

```markdown
Instantaneous Decoding Refresh
1. I帧:帧内编码帧是一种自带全部信息的独立帧，无需参考其他图像便可独立进行解码，视频序列中的第一个帧始终都是I帧。
 		I和IDR帧都是使用帧内预测的。它们都是同一个东西而已,在编码和解码中为了方便，要首个I帧和其他I帧区别开，所以才把第一个首个I帧叫IDR，这样就方便控制编码和解码流程。 IDR帧的作用是立刻刷新,使错误不致传播,从IDR帧开始,重新算一个新的序列开始编码。而I帧不具有随机访问的能力，这个功能是由IDR承担。 IDR会导致DPB（DecodedPictureBuffer 参考帧列表——这是关键所在）清空，而I不会。IDR图像一定是I图像，但I图像不一定是IDR图像。一个序列中可以有很多的I图像，I图像之后的图像可以引用I图像之间的图像做运动参考。一个序列中可以有很多的I图像，I图像之后的图象可以引用I图像之间的图像做运动参考。 
   		对于IDR帧来说，在IDR帧之后的所有帧都不能引用任何IDR帧之前的帧的内容，与此相反，对于普通的I-帧来说，位于其之后的B-和P-帧可以引用位于普通I-帧之前的I-帧。从随机存取的视频流中，播放器永远可以从一个IDR帧播放，因为在它之后没有任何帧引用之前的帧。但是，不能在一个没有IDR帧的视频中从任意点开始播放，因为后面的帧总是会引用前面的帧 。
  		收到 IDR 帧时，解码器另外需要做的工作就是：把所有的 PPS 和 SPS 参数进行更新。
  		对IDR帧的处理(与I帧的处理相同)：(1) 进行帧内预测，决定所采用的帧内预测模式。(2) 像素值减去预测值，得到残差。(3) 对残差进行变换和量化。(4) 变长编码和算术编码。(5) 重构图像并滤波，得到的图像作为其它帧的参考帧。
  		多参考帧情况下，  举个例子 ：有如下帧序列： IPPPP I P PPP ……。按照 3 个参考帧编码。因为“按照 3 个参考帧编码”，所以参考帧队列长度为 3 。
  		遇到绿色的 I 时，并不清空参考帧队列，把这个 I 帧加入参考帧队列（当然 I 编码时不用参考帧。）。再检测到红色的 P 帧时，用到的就是 PPI 三帧做参考了。
2. P帧:前向预测编码帧
		在针对连续动态图像编码时，将连续若干幅图像分成P,B,I三种类型，P帧由在它前面的P帧或者I帧预测而来，它比较与它前面的P帧或者I帧之间的相同信息或数据，也即考虑运动的特性进行帧间压缩。P帧法是根据本帧与相邻的前一帧（I帧或P帧）的不同点来压缩本帧数据。采取P帧和I帧联合压缩的方法可达到更高的压缩且无明显的压缩痕迹。
		P帧的预测与重构:P帧是以I帧为参考帧，在I帧中找出P帧“某点”预测值和运动矢量，取预测差值和运动矢量一起传送。在接收端根据运动矢量从I帧中找出P帧“某点”的预测值并与差值相加以得到P帧某点样值，从而可得到完整的P帧。
		有的视频序列比较简单，就没有B帧.
3. B帧：双向预测内插编码帧
		B帧的预测与重构
    	B帧法是双向预测的帧间压缩算法。当把一帧压缩成B帧时，它根据相邻的前一帧、本帧以及后一帧数据的不同点来压缩本帧，也即仅记录本帧与前后帧的差值。只有采用B帧压缩才能达到200：1的高压缩。
     	B帧是以前面的I或P帧和后面的P帧为参考帧，找出B帧“某点”的预测值和两个运动矢量，并取预测差值和运动矢量传送。接收端根据运动矢量在两个参考帧中。
```

#### b.	GOP

​    Group of Picture，关键帧的周期，也就是两个IDR帧之间的距离，一个帧组的最大帧数，一般而言，每一秒视频至少需要使用 1 个关键帧。增加关键帧个数可改善质量，但是同时增加带宽和网络负载。在一个GOP中，P、B帧是由I帧预测得到的，当I帧的图像质量比较差时，会影响到一个GOP中后续P、B帧的图像质量，直到下一个GOP 开始才有可能得以恢复，所以GOP值也不宜设置过大。

​    同时，由于P、B帧的复杂度大于I帧，所以过多的P、B帧会影响编码效率，使编码效率降低。另外，过长的GOP还会影响Seek操作的响应速度，由于P、B帧是由前面的I或P帧预测得到的，所以Seek操作需要直接定位，解码某一个P或B帧时，需要先解码得到本GOP内的I帧及之前的N个预测帧才可以，GOP值越长，需要解码的预测帧就越多，seek响应的时间也越长。

 

#### c.	采样率

​    指将[模拟](https://www.baidu.com/s?wd=模拟&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd)信号转换成数字信号时的采样频率，也就是单位时间内采样多少点。一个采样点数据有多少个比特。比特率是指每秒传送的比特(bit)数。单位为 bps(Bit Per Second)，比特率越高，传送的数据越大，音质越好。比特率 = 采样率 × 采用位数 × [声道数](https://www.baidu.com/s?wd=声道数&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd).

 

#### d.	比特率

​    比特率是指每秒传送的比特(bit)数。单位为bps(Bit Per Second)，比特率越高，传送的数据越大。在视频领域。比特率是指将数字声音、视频由模拟格式转化成数字格式的采样率，采样率越高，还原后的音质、画质就越好。

​    比特率表示经过编码（压缩）后的音、视频数据每秒钟需要用多少个比特来表示，而比特就是二进制里面最小的单位，要么是0，要么是1。比特率与音、视频压缩的关系，简单的说就是比特率越高，音、视频的质量就越好，但编码后的文件就越大；如果比特率越少则情况刚好相反。

 

#### e.	分辨率

​    就是帧大小每一帧就是一副图像。640*480分辨率的视频，建议视频的码率设置在700以上，音频采样率44100就行了。一个音频编码率为128Kbps，视频编码率为800Kbps的文件，其总编码率为928Kbps，意思是经过编码后的数据每秒钟需要用928K比特来表示。

​    计算输出文件大小公式：[音频编码率（KBit）/8 +视频编码率（KBit）/8]×影片总长度（秒）=文件大小（MB）

 

#### f.	码流/码率

​    码流(Data Rate)是指视频文件在单位时间内使用的数据流量，也叫码率或码流率，通俗一点的理解就是取样率,是视频编码中画面质量控制中最重要的部分，一般我们用的单位是kb/s或者Mb/s。一般来说同样分辨率下，视频文件的码流越大，压缩比就越小，画面质量就越高。码流越大，说明单位时间内取样率越大，数据流，精度就 越高，处理出来的文件就越接近原始文件，图像质量越好，画质越清晰，要求播放设备的解码能力也越高。

​    当然，码流越大，文件体积也越大，其计算公式是文件体积=时间X码率/8。例如，网络上常见的一部90分钟1Mbps码流的720P RMVB文件，其体积就=5400秒×1Mb/8=675MB。

​    通常来说，一个视频文件包括了画面及声音，例如一个RMVB的视频文件，里面包含了视频信息和音频信息，音频及视频都有各自不同的采样方式和比特率， 也就是说，同一个视频文件音频和视频的比特率并不是一样的。而我们所说的一个视频文件码流率大小，一般是指视频文件中音频及视频信息码流率的总和。

​    以国内最流行，大家最熟悉的RMVB视频文件为例，RMVB中的VB，指的是VBR，即Variable Bit Rate的缩写，中文含义是可变比特率，它表示RMVB采用的是动态编码的方式，把较高的采样率用于复杂的动态画面(歌舞、飞车、战争、动作等)，而把较低的采样率用于静态画面，合理利用资源，达到画质与体积可兼得的效果。

​    码率设置时，一般需考虑三个因素：

​    1、分辨率 　

​    分辨率是决定位率（码率）的主要因素，不同的分辨率要采用不同的位率。总体而言，录像的分辨率越高，所要求的位率（码率）也越大，但并不总是如此，图1说明了不同分辨率的合理的码率选择范围。所谓“合理的范围”指的是，如果低于这个范围，图像质量看起来会变得不可接受；如果高于这个范围，则显得没有必要，对于网络资源以及存储资源来说是一种浪费。 　

​    2、场景 　

​    监控的场景是设置码率时要考虑的第二个因素。在视频监控中，图像的运动剧烈程度还与位率有一定的关系，运动越剧烈，编码所要求的码率就越高。反之则越低。因此在同样的图像分辨率条件下，监控人多的场景和人少的场景，所要求的位率也是不同的。 　

​    3、存储空间 　

​    最后需要考量的因素是存储空间，这个因素主要是决定了录像系统的成本。位率设置得越高，画质相对会越好，但所要求的存储空间就越大。所以在工程实施中，设置合适的位率即可以保证良好的回放图像质量，又可以避免不必要的资源浪费。 　

 

#### g.	 码率控制算法

​    动态调整编码器参数，得到目标比特数。为视频序列中的图像组GOP、图像或子图像分配一定的比特。现有的码率控制算法主要是通过调整离散余弦变换的量化参数（QP）大小输出目标码率。

#### h.	fps

​    Frames Per Second，帧率，缩写为帧/秒。是指每秒钟刷新的图片的帧数，也可以理解为图形处理器每秒钟能够刷新几次。越高的帧速率可以得到更流畅、更逼真的动画。每秒钟帧数(fps)越多，所显示的动作就会越流畅。

 

#### i.	profile level

​    分别是BP、EP、MP、HP：

​    1、BP-Baseline Profile：基本画质。支持I/P 帧，只支持无交错（Progressive）和CAVLC；

​    2、EP-Extended profile：进阶画质。支持I/P/B/SP/SI 帧，只支持无交错（Progressive）和CAVLC；

​    3、MP-Main profile：主流画质。提供I/P/B 帧，支持无交错（Progressive）和交错（Interlaced），也支持CAVLC 和CABAC 的支持；

​    4、HP-High profile：高级画质。在main Profile 的基础上增加了8x8内部预测、自定义量化、无损视频编码和更多的YUV 格式。



### 6.RTMP流媒体播放过程

RTMP协议规定，播放一个流媒体有两个前提步骤：第一步，建立一个网络连接（NetConnection）；第二步，建立一个网络流（NetStream）。其中，网络连接代表服务器端应用程序和客户端之间基础的连通关系。网络流代表了发送多媒体数据的通道。服务器和客户端之间只能建立一个网络连接，但是基于该连接可以创建很多网络流。他们的关系如图所示：

![img](https://img-blog.csdn.net/20130915111501437?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

1 简要介绍

播放一个RTMP协议的流媒体需要经过以下几个步骤：握手，建立连接，建立流，播放。RTMP连接都是以握手作为开始的。建立连接阶段用于建立客户端与服务器之间的“网络连接”；建立流阶段用于建立客户端与服务器之间的“网络流”；播放阶段用于传输视音频数据。

2 握手（HandShake）

一个RTMP连接以握手开始，双方分别发送大小固定的三个数据块

a)        握手开始于客户端发送C0、C1块。服务器收到C0或C1后发送S0和S1。

b)        当客户端收齐S0和S1后，开始发送C2。当服务器收齐C0和C1后，开始发送S2。

c)        当客户端和服务器分别收到S2和C2后，握手完成。



![img](https://img-blog.csdn.net/20130915111408781?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)


​																										握手

 

 

3建立网络连接（NetConnection）

a)        客户端发送命令消息中的“连接”(connect)到服务器，请求与一个服务应用实例建立连接。

b)        服务器接收到连接命令消息后，发送确认窗口大小(Window Acknowledgement Size)协议消息到客户端，同时连接到连接命令中提到的应用程序。

c)        服务器发送设置带宽()协议消息到客户端。

d)        客户端处理设置带宽协议消息后，发送确认窗口大小(Window Acknowledgement Size)协议消息到服务器端。

e)        服务器发送用户控制消息中的“流开始”(Stream Begin)消息到客户端。

f)         服务器发送命令消息中的“结果”(_result)，通知客户端连接的状态。

![img](https://img-blog.csdn.net/20130915111423578?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)


​																											建立连接

4建立网络流（NetStream）

a)      客户端发送命令消息中的“创建流”（createStream）命令到服务器端。

b)      服务器端接收到“创建流”命令后，发送命令消息中的“结果”(_result)，通知客户端流的状态。

![img](https://img-blog.csdn.net/20130915111350062?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)


​																											建立流

 

5 播放（Play）

a)        客户端发送命令消息中的“播放”（play）命令到服务器。

b)        接收到播放命令后，服务器发送设置块大小（ChunkSize）协议消息。

c)        服务器发送用户控制消息中的“streambegin”，告知客户端流ID。

d)        播放命令成功的话，服务器发送命令消息中的“响应状态” NetStream.Play.Start & NetStream.Play.reset，告知客户端“播放”命令执行成功。

e)        在此之后服务器发送客户端要播放的音频和视频数据。



![img](https://img-blog.csdn.net/20130915111446703?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

​																											播放流